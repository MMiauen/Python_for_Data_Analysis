## 6.2 二进制格式
pickle是Python内建的序列化模块，用于对数据进行二进制格式操作，也称序列化。

Pandas对象拥有一个to_pickle方法，可以将数据以pickle格式写入硬盘，被“pickle化”的对象又可通过read_pickle来读取：


```python
import pandas as pd
frame=pd.read_csv('F:利用python进行数据分析\examples.csv')
frame
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>a</th>
      <th>b</th>
      <th>c</th>
      <th>d</th>
      <th>message</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1</td>
      <td>2</td>
      <td>3</td>
      <td>4</td>
      <td>hello</td>
    </tr>
    <tr>
      <td>1</td>
      <td>5</td>
      <td>6</td>
      <td>7</td>
      <td>8</td>
      <td>world</td>
    </tr>
    <tr>
      <td>2</td>
      <td>9</td>
      <td>10</td>
      <td>11</td>
      <td>12</td>
      <td>foo</td>
    </tr>
  </tbody>
</table>
</div>




```python
frame.to_pickle('F:利用python进行数据分析\examples_pickle')  # 原CSV数据被pickle化，在该路径中生成一个名为examples_pickle的新文件
```


```python
pd.read_pickle('F:利用python进行数据分析\examples_pickle')  # 使用read_pickle又把该pickle文件读取出来
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>a</th>
      <th>b</th>
      <th>c</th>
      <th>d</th>
      <th>message</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1</td>
      <td>2</td>
      <td>3</td>
      <td>4</td>
      <td>hello</td>
    </tr>
    <tr>
      <td>1</td>
      <td>5</td>
      <td>6</td>
      <td>7</td>
      <td>8</td>
      <td>world</td>
    </tr>
    <tr>
      <td>2</td>
      <td>9</td>
      <td>10</td>
      <td>11</td>
      <td>12</td>
      <td>foo</td>
    </tr>
  </tbody>
</table>
</div>



pickle仅被推荐作为短期的存储格式，因为一个今天被序列化的对象明天可能就因为库的更新而无法反序列化。

Pandas内建还支持其他两个二进制格式：HDF5和MessagePack

### 6.2.1使用HDF5格式
HDF5用于存储大量科学数组数据，是一种备受好评的文件格式，它以C库形式提供，并具有许多语言接口，例如Java、MATLAB、Python等

HDF5中“HDF”表示分层数据格式，每个HDF5文件可以存储多个数据集并支持元数据；HDF5支持多种压缩模式的即时压缩，使得重复模式的数据可以更高效存储；HDF5适用于处理超大型数据，因为它能支持高效读写大型数组中的一小块。 

【？？？】

### 6.2.2 读取Microsoft Excel文件
想将XLS或XLSX文件读取到DataFrame中，可以使用Pandas中的 read_excel


```python
import pandas as pd
frame=pd.read_excel('F:利用python进行数据分析\examples.xls')
##如果读取的是含有多个表的文件，你还可以选择读取那一页：pd.read_excel('path','sheet2') 表明读取路径文件下的第二页
```

如果想将Pandas数据写入Excel格式中，你可以使用 to_excel


```python
frame.to_excel('F:利用python进行数据分析\examples2.xls') 
# frame是Pandas中的数据内容，运行程序后在该路径下创建了一个新的名为examples2的Excel表格，内容为frame
```

## 6.3 于Web API交互
很多网站都有公开API，并通过JSON等其他格式提供数据服务。如果利用Python来访问API获取数据，推荐使用最简单的requests包。

例如：我们想获取GitHub上最新的30条关于Pandas的问题，我们可以使用附加库requests发送一个HTTP GET 请求：


```python
import pandas as pd
import requests
url='https://api.github.com/repos/pandas-dev/pandas/issues'
resp=requests.get(url)
resp
```




    <Response [200]>




```python
data=resp.json() #响应对象resp的json方法将返回一个包含解析为本地Python对象的JSON字典
data[0]['title']
```




    'REGR: <th> tags for notebook display closes #28204'



data中的每一个元素都是一个包含GitHub问题页面上的所有数据的字典（注释除外），我们可以将data直接传给DataFrame，并提取感兴趣的字段


```python
issues=pd.DataFrame(data,columns=['number','title','labels','state'])
issues
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>number</th>
      <th>title</th>
      <th>labels</th>
      <th>state</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>28216</td>
      <td>REGR: &lt;th&gt; tags for notebook display closes #2...</td>
      <td>[{'id': 57395487, 'node_id': 'MDU6TGFiZWw1NzM5...</td>
      <td>open</td>
    </tr>
    <tr>
      <td>1</td>
      <td>28215</td>
      <td>Add function to clean up column names with spe...</td>
      <td>[]</td>
      <td>open</td>
    </tr>
    <tr>
      <td>2</td>
      <td>28213</td>
      <td>BUG: Fix issue with apply on empty DataFrame</td>
      <td>[]</td>
      <td>open</td>
    </tr>
    <tr>
      <td>3</td>
      <td>28212</td>
      <td>I think I submitted a pull request to this eff...</td>
      <td>[]</td>
      <td>open</td>
    </tr>
    <tr>
      <td>4</td>
      <td>28210</td>
      <td>cannot output csv with IntervalIndex</td>
      <td>[]</td>
      <td>open</td>
    </tr>
    <tr>
      <td>5</td>
      <td>28209</td>
      <td>STY: whitespace before class docstringsd</td>
      <td>[{'id': 106935113, 'node_id': 'MDU6TGFiZWwxMDY...</td>
      <td>open</td>
    </tr>
    <tr>
      <td>6</td>
      <td>28207</td>
      <td>Localizing dates to a timezone with dls after ...</td>
      <td>[{'id': 307649777, 'node_id': 'MDU6TGFiZWwzMDc...</td>
      <td>open</td>
    </tr>
    <tr>
      <td>7</td>
      <td>28205</td>
      <td>CLN: avoid catching Exception in _choose_path</td>
      <td>[]</td>
      <td>open</td>
    </tr>
    <tr>
      <td>8</td>
      <td>28204</td>
      <td>CSS selector for index cells</td>
      <td>[{'id': 76811, 'node_id': 'MDU6TGFiZWw3NjgxMQ=...</td>
      <td>open</td>
    </tr>
    <tr>
      <td>9</td>
      <td>28203</td>
      <td>CLN: catch less inside try/except</td>
      <td>[]</td>
      <td>open</td>
    </tr>
    <tr>
      <td>10</td>
      <td>28202</td>
      <td>DataFrame.nunique and Series.nunique not consi...</td>
      <td>[{'id': 76811, 'node_id': 'MDU6TGFiZWw3NjgxMQ=...</td>
      <td>open</td>
    </tr>
    <tr>
      <td>11</td>
      <td>28198</td>
      <td>CLN: Catch more specific exception in groupby.ops</td>
      <td>[]</td>
      <td>open</td>
    </tr>
    <tr>
      <td>12</td>
      <td>28195</td>
      <td>TYPING: add skeleton stub for Timestamp</td>
      <td>[{'id': 1280988427, 'node_id': 'MDU6TGFiZWwxMj...</td>
      <td>open</td>
    </tr>
    <tr>
      <td>13</td>
      <td>28194</td>
      <td>BUG : DataFrameGroupBy.quantile segfault</td>
      <td>[]</td>
      <td>open</td>
    </tr>
    <tr>
      <td>14</td>
      <td>28193</td>
      <td>pd.to_datetime() does not respect exact format...</td>
      <td>[]</td>
      <td>open</td>
    </tr>
    <tr>
      <td>15</td>
      <td>28192</td>
      <td>Rolling with offset and axis=1</td>
      <td>[{'id': 76811, 'node_id': 'MDU6TGFiZWw3NjgxMQ=...</td>
      <td>open</td>
    </tr>
    <tr>
      <td>16</td>
      <td>28191</td>
      <td>dataframe's index is blank,</td>
      <td>[]</td>
      <td>open</td>
    </tr>
    <tr>
      <td>17</td>
      <td>28190</td>
      <td>Feature request: groupby on columns with overl...</td>
      <td>[{'id': 233160, 'node_id': 'MDU6TGFiZWwyMzMxNj...</td>
      <td>open</td>
    </tr>
    <tr>
      <td>18</td>
      <td>28189</td>
      <td>Merge on CategoricalIndex fails if left_index=...</td>
      <td>[{'id': 76811, 'node_id': 'MDU6TGFiZWw3NjgxMQ=...</td>
      <td>open</td>
    </tr>
    <tr>
      <td>19</td>
      <td>28188</td>
      <td>Slow (and weird) empty dataframe creation</td>
      <td>[{'id': 8935311, 'node_id': 'MDU6TGFiZWw4OTM1M...</td>
      <td>open</td>
    </tr>
    <tr>
      <td>20</td>
      <td>28187</td>
      <td>DOC: Fix PR08 in docstrings</td>
      <td>[]</td>
      <td>open</td>
    </tr>
    <tr>
      <td>21</td>
      <td>28185</td>
      <td>DOC: Fix docs on merging categoricals.</td>
      <td>[{'id': 134699, 'node_id': 'MDU6TGFiZWwxMzQ2OT...</td>
      <td>open</td>
    </tr>
    <tr>
      <td>22</td>
      <td>28184</td>
      <td>REF: import _libs.reduction as libreduction</td>
      <td>[{'id': 211029535, 'node_id': 'MDU6TGFiZWwyMTE...</td>
      <td>open</td>
    </tr>
    <tr>
      <td>23</td>
      <td>28183</td>
      <td>BUG: to_html() with formatters=&lt;list&gt; and max_...</td>
      <td>[]</td>
      <td>open</td>
    </tr>
    <tr>
      <td>24</td>
      <td>28182</td>
      <td>Example for adding a calculated column in SQL ...</td>
      <td>[{'id': 134699, 'node_id': 'MDU6TGFiZWwxMzQ2OT...</td>
      <td>open</td>
    </tr>
    <tr>
      <td>25</td>
      <td>28181</td>
      <td>ENH: Enable read_csv interpret 'Infinity' as f...</td>
      <td>[{'id': 47229171, 'node_id': 'MDU6TGFiZWw0NzIy...</td>
      <td>open</td>
    </tr>
    <tr>
      <td>26</td>
      <td>28180</td>
      <td>to_iso methods for DatetimeLikeArray</td>
      <td>[{'id': 49379259, 'node_id': 'MDU6TGFiZWw0OTM3...</td>
      <td>open</td>
    </tr>
    <tr>
      <td>27</td>
      <td>28179</td>
      <td>DOC: Add missing public plotting functions to ...</td>
      <td>[{'id': 134699, 'node_id': 'MDU6TGFiZWwxMzQ2OT...</td>
      <td>open</td>
    </tr>
    <tr>
      <td>28</td>
      <td>28178</td>
      <td>BUG: descriptor 'axes' for 'BlockManager' obje...</td>
      <td>[{'id': 47229171, 'node_id': 'MDU6TGFiZWw0NzIy...</td>
      <td>open</td>
    </tr>
    <tr>
      <td>29</td>
      <td>28177</td>
      <td>DEPR: Clean up of pandas.plotting</td>
      <td>[{'id': 87485152, 'node_id': 'MDU6TGFiZWw4NzQ4...</td>
      <td>open</td>
    </tr>
  </tbody>
</table>
</div>



## 6.4 与数据库交互
业务场景中，大部分数据并不是存储在文本或Excel文件中的，而是基于SQL的关系型数据库（例如SQL Server、MySQL、PostgreSQL），从SQL中将数据读取为DataFrame非常简单。

呜呜呜看不懂，用到的时候再说8
